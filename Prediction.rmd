---
title: "Prediction of Diabetes"
author: "Sridhar"
date: "August 8, 2018"
output: 
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

## Loading the required libraries
```{r}
library(ggplot2)
library(corrplot)
library(caTools)
library(ROCR)
```

## Load the data
The observations of the people are stored in a CSV format, named diabetes.csv.The data is loaded in the environment.Let's check how the data is structured.
```{r}
data = read.csv("diabetes.csv")
head(data)
```

## Correlations

The proportionalities of the attributes of the data can be identified by the  correlation coefficient,either numerically or visually.
```{r}
correlations <- cor(data)
correlations
corrplot(correlations, method="color")
```

## Visualization
Visualizations are used to grasp the structure of data and its relations,like how they vary and their 
relationships with the otehr data.They are said to be EDA.

A matrix of scatterplots is produce for this dataset.
```{r}
pairs(data, col=data$Outcome)
```


## Preparing the data

The dataset is divided as two parts, training data and testing data, with a Splitratio of 0.75. It means that 2/3rds of the data is labelled by training set and the rest 1/3rd of data is the testing set.The division of the dataset is by means of a random order generated by the seed.
```{r}
set.seed(88)
split <- sample.split(data$Outcome, SplitRatio = 0.75)
data_train <- subset(data, split == TRUE)
data_test <- subset(data, split == FALSE)
```



## Logistic regression

The Logistic regression helps to classify the concern person will get diabetes or not.Since we are using the logistic regression we have to mention that, family = binomial.We are using all the attributes we have in the dataset.Let us take a look at the summary.
```{r}
model <- glm (Outcome ~ .-Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age, data = data_train, family = binomial)
summary(model)
```

```{r}
predict_train <- predict(model, type = 'response')
predict_test <- predict(model, newdata = data_test, type = 'response')

```

```{r}
table(data_train$Outcome, predict_train > 0.5)
```

```{r}

ROCRpred <- prediction(predict_train, data_train$Outcome)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))

```

## Comparison

By comparing the real values with the real data, we can see the how our machine learning algorithm performs !
```{r}
predict_test_c = predict_test
i = 1
while(i <= length(predict_test))
{
  if(predict_test[i] < 0.5)
    predict_test_c[i] = 0
  else
    predict_test_c[i] = 1
  i = i + 1;
}
compare <- data.frame(data_test$Outcome,predict_test_c)
colnames(compare) <- c("Observed Values","Predicted values")
ggplot(data = compare,aes(x = "Observed Values", y = "Predicted values")) + geom_abline() +
  xlab("Observed Values") + ylab("Predicted values") + theme_classic()
compare
```

## Conclusion

The results can be improved by applyting the feature scaling and data cleaning.From this project we predict the type 2 diabetes, commonly called as diabetes mellitus.As a result it can help to improve their health conditions.
